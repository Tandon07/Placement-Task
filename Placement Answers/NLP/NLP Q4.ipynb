{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5262c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f677931",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'scipy.sparse' has no attribute 'coo_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 68\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39mencoding) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     66\u001b[0m     text \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m---> 68\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[43msummarize_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummary:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(summary)\n",
      "Cell \u001b[1;32mIn[20], line 48\u001b[0m, in \u001b[0;36msummarize_text\u001b[1;34m(text, num_sentences)\u001b[0m\n\u001b[0;32m     45\u001b[0m graph \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mfrom_numpy_array(similarity_matrix)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Calculate the sentence scores using PageRank algorithm\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpagerank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Sort the sentences based on their scores\u001b[39;00m\n\u001b[0;32m     51\u001b[0m ranked_sentences \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(((scores[i], sentence) \u001b[38;5;28;01mfor\u001b[39;00m i, sentence \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(preprocessed_text)), reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\networkx\\algorithms\\link_analysis\\pagerank_alg.py:108\u001b[0m, in \u001b[0;36mpagerank\u001b[1;34m(G, alpha, personalization, max_iter, tol, nstart, weight, dangling)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpagerank\u001b[39m(\n\u001b[0;32m     10\u001b[0m     G,\n\u001b[0;32m     11\u001b[0m     alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.85\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     dangling\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     18\u001b[0m ):\n\u001b[0;32m     19\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the PageRank of the nodes in the graph.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m    PageRank computes a ranking of the nodes in the graph G based on\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    106\u001b[0m \n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpagerank_scipy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpersonalization\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdangling\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\networkx\\algorithms\\link_analysis\\pagerank_alg.py:469\u001b[0m, in \u001b[0;36mpagerank_scipy\u001b[1;34m(G, alpha, personalization, max_iter, tol, nstart, weight, dangling)\u001b[0m\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}\n\u001b[0;32m    468\u001b[0m nodelist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(G)\n\u001b[1;32m--> 469\u001b[0m A \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_scipy_sparse_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodelist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodelist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m S \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    471\u001b[0m S[S \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m S[S \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\networkx\\convert_matrix.py:921\u001b[0m, in \u001b[0;36mto_scipy_sparse_array\u001b[1;34m(G, nodelist, dtype, weight, format)\u001b[0m\n\u001b[0;32m    919\u001b[0m         r \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m diag_index\n\u001b[0;32m    920\u001b[0m         c \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m diag_index\n\u001b[1;32m--> 921\u001b[0m     A \u001b[38;5;241m=\u001b[39m \u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoo_array\u001b[49m((d, (r, c)), shape\u001b[38;5;241m=\u001b[39m(nlen, nlen), dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m A\u001b[38;5;241m.\u001b[39masformat(\u001b[38;5;28mformat\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'scipy.sparse' has no attribute 'coo_array'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "\n",
    "    # Tokenize into words\n",
    "    words = [word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "    # Remove stopwords and perform stemming\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    ps = PorterStemmer()\n",
    "    words = [[ps.stem(word) for word in sentence if word.lower() not in stop_words] for sentence in words]\n",
    "\n",
    "    return words\n",
    "\n",
    "def get_sentence_similarity_matrix(sentences):\n",
    "    # Flatten the list of sentences into a single list of words\n",
    "    words = [word for sentence in sentences for word in sentence]\n",
    "\n",
    "    # Create a TF-IDF vectorizer\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(words)\n",
    "\n",
    "    # Calculate the cosine similarity matrix\n",
    "    similarity_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "    return similarity_matrix\n",
    "\n",
    "def summarize_text(text, num_sentences=3):\n",
    "    # Preprocess the text\n",
    "    preprocessed_text = preprocess_text(text)\n",
    "\n",
    "    # Calculate the sentence similarity matrix\n",
    "    similarity_matrix = get_sentence_similarity_matrix(preprocessed_text)\n",
    "\n",
    "    # Create a graph from the similarity matrix\n",
    "    graph = nx.from_numpy_array(similarity_matrix)\n",
    "\n",
    "    # Calculate the sentence scores using PageRank algorithm\n",
    "    scores = nx.pagerank(graph)\n",
    "\n",
    "    # Sort the sentences based on their scores\n",
    "    ranked_sentences = sorted(((scores[i], sentence) for i, sentence in enumerate(preprocessed_text)), reverse=True)\n",
    "\n",
    "    # Select the top sentences for the summary\n",
    "    top_sentences = [sentence for score, sentence in ranked_sentences[:num_sentences]]\n",
    "\n",
    "    # Flatten the selected sentences into a single string\n",
    "    summary = ' '.join([' '.join(sentence) for sentence in top_sentences])\n",
    "\n",
    "    return summary\n",
    "\n",
    "# Example usage\n",
    "file_path = r'C:\\Users\\tando\\Downloads\\filee.txt'\n",
    "encoding = 'utf-8'  # Try different encodings if the default encoding causes an error\n",
    "\n",
    "with open(file_path, 'r', encoding=encoding) as file:\n",
    "    text = file.read()\n",
    "\n",
    "summary = summarize_text(text)\n",
    "print(\"Summary:\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33ec483",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
