{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tBrN9v149NSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pytube import YouTube\n",
        "\n",
        "# Define the YouTube video URL\n",
        "video_url = \"https://youtu.be/iuL3caE31mY\"\n",
        "\n",
        "# Download the YouTube video using pytube\n",
        "yt = YouTube(video_url)\n",
        "video = yt.streams.first()\n",
        "video.download()\n",
        "\n",
        "# Extract the comments from the downloaded video\n",
        "comments = []\n",
        "for comment in yt.comments:\n",
        "    comments.append(comment.text)\n",
        "\n",
        "# Create a DataFrame to store the comments\n",
        "df = pd.DataFrame({'comment': comments})\n",
        "\n",
        "# Save the comments in a CSV file\n",
        "df.to_csv('comments.csv', index=False)"
      ],
      "metadata": {
        "id": "K0oy-aMO9NPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4x5a1TWy8Y_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Load the comments from the CSV file into a DataFrame\n",
        "df = pd.read_csv('comments.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform sentiment analysis on each comment\n",
        "df['sentiment'] = df['Comment'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
        "\n",
        "# Determine the most positive and negative comments\n",
        "most_positive_comment = df.loc[df['sentiment'].idxmax(), 'Comment']\n",
        "most_negative_comment = df.loc[df['sentiment'].idxmin(), 'Comment']\n",
        "\n",
        "# Print the most positive and negative comments\n",
        "print(\"Most Positive Comment:\")\n",
        "print(most_positive_comment)\n",
        "print()\n",
        "print(\"Most Negative Comment:\")\n",
        "print(most_negative_comment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "We5a84vr09DT",
        "outputId": "86e6e134-79b9-47d2-b6f1-3f73a3453714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Positive Comment:\n",
            "Great work bro üëçüëè\n",
            "\n",
            "Most Negative Comment:\n",
            "Shameful.... Horrifying\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download NLTK resources (if not already downloaded)\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Set up stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Tokenize the comments and extract keywords\n",
        "df['keywords'] = df['Comment'].apply(lambda x: [word for word in word_tokenize(x.lower()) if word.isalpha() and word not in stop_words])\n",
        "\n",
        "# Flatten the list of keywords\n",
        "all_keywords = [word for keywords in df['keywords'] for word in keywords]\n",
        "\n",
        "# Get the top 10 most frequently mentioned keywords\n",
        "top_keywords = nltk.FreqDist(all_keywords).most_common(10)\n",
        "\n",
        "# Print the 10 most demanding topics\n",
        "print(\"10 Most Demanding Topics:\")\n",
        "for keyword, frequency in top_keywords:\n",
        "    print(f\"{keyword}: {frequency} mentions\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFazzKxw16z0",
        "outputId": "a9904946-6910-494a-dd8d-5622e53525a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 Most Demanding Topics:\n",
            "ai: 64 mentions\n",
            "people: 12 mentions\n",
            "human: 10 mentions\n",
            "jobs: 10 mentions\n",
            "dangerous: 9 mentions\n",
            "also: 8 mentions\n",
            "new: 8 mentions\n",
            "even: 8 mentions\n",
            "would: 8 mentions\n",
            "good: 7 mentions\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytube\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9imC6ah2ywT",
        "outputId": "0e2d25d5-6cef-4ea3-ad4f-cc58e58e232e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gJNRWmAc34bR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4RTM3bCp2_Dl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pwstCQGn34d_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q4ZV1yDs35xL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}