{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-02T10:27:44.427175Z","iopub.execute_input":"2023-06-02T10:27:44.428043Z","iopub.status.idle":"2023-06-02T10:27:49.617851Z","shell.execute_reply.started":"2023-06-02T10:27:44.428009Z","shell.execute_reply":"2023-06-02T10:27:49.616722Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Define the CNN architectures\n\n# Architecture 1: Simple CNN with two convolutional layers\nclass SimpleCNN(nn.Module):\n    def __init__(self):\n        super(SimpleCNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n        self.relu1 = nn.ReLU()\n        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.relu2 = nn.ReLU()\n        self.fc = nn.Linear(32 * 32 * 32, 10)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.relu1(x)\n        x = self.conv2(x)\n        x = self.relu2(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\n\n# Architecture 2: LeNet-5\nclass LeNet5(nn.Module):\n    def __init__(self):\n        super(LeNet5, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n        self.relu1 = nn.ReLU()\n        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n        self.relu2 = nn.ReLU()\n        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.relu3 = nn.ReLU()\n        self.fc2 = nn.Linear(120, 84)\n        self.relu4 = nn.ReLU()\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.relu1(x)\n        x = self.maxpool1(x)\n        x = self.conv2(x)\n        x = self.relu2(x)\n        x = self.maxpool2(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc1(x)\n        x = self.relu3(x)\n        x = self.fc2(x)\n        x = self.relu4(x)\n        x = self.fc3(x)\n        return x\n\n\n# Architecture 3: Custom CNN with three convolutional layers\nclass CustomCNN(nn.Module):\n    def __init__(self):\n        super(CustomCNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n        self.relu1 = nn.ReLU()\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.relu2 = nn.ReLU()\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.relu3 = nn.ReLU()\n        self.fc = nn.Linear(128 * 32 * 32, 10)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.relu1(x)\n        x = self.conv2(x)\n        x = self.relu2(x)\n        x = self.conv3(x)\n        x = self.relu3(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\n\n# Architecture 4: MobileNetV2\nclass MobileNetV2(nn.Module):\n    def __init__(self):\n        super(MobileNetV2, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, groups=32),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(32, 64, kernel_size=1, stride=1, padding=0),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, groups=64),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 128, kernel_size=1, stride=1, padding=0),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, groups=128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=1, stride=1, padding=0),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1, groups=128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 256, kernel_size=1, stride=1, padding=0),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, groups=256),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=1, stride=1, padding=0),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1, groups=256),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 512, kernel_size=1, stride=1, padding=0),\n            nn.ReLU(inplace=True),\n            nn.AdaptiveAvgPool2d((1, 1)),\n        )\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(512, 10),\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n\n# Architecture 5: VGG-like network with three convolutional layers\nclass VGGLike(nn.Module):\n    def __init__(self):\n        super(VGGLike, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        )\n        self.classifier = nn.Sequential(\n            nn.Linear(256 * 8 * 8, 512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(512, 512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(512, 10),\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-02T10:45:28.346690Z","iopub.execute_input":"2023-06-02T10:45:28.347044Z","iopub.status.idle":"2023-06-02T10:45:28.380139Z","shell.execute_reply.started":"2023-06-02T10:45:28.347014Z","shell.execute_reply":"2023-06-02T10:45:28.379107Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Define the function to train and evaluate the models\ndef train_model(model, train_loader, optimizer, criterion):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n\n\ndef evaluate_model(model, test_loader):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            output = model(data)\n            _, predicted = torch.max(output.data, 1)\n            total += target.size(0)\n            correct += (predicted == target).sum().item()\n    accuracy = 100.0 * correct / total\n    return accuracy\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-02T10:28:52.220213Z","iopub.execute_input":"2023-06-02T10:28:52.220882Z","iopub.status.idle":"2023-06-02T10:28:52.228153Z","shell.execute_reply.started":"2023-06-02T10:28:52.220849Z","shell.execute_reply":"2023-06-02T10:28:52.227252Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Load the CIFAR-10 dataset and apply transformations\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomCrop(32, padding=4),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n\ntrain_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\ntest_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n\n# Create data loaders\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-02T10:29:12.407860Z","iopub.execute_input":"2023-06-02T10:29:12.408215Z","iopub.status.idle":"2023-06-02T10:29:18.507718Z","shell.execute_reply.started":"2023-06-02T10:29:12.408187Z","shell.execute_reply":"2023-06-02T10:29:18.506803Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170498071/170498071 [00:01<00:00, 101904006.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/cifar-10-python.tar.gz to ./data\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\n\n# Architecture 1: Simple CNN\nmodel1 = SimpleCNN()\noptimizer1 = optim.Adam(model1.parameters(), lr=0.001)\n\n# Architecture 2: LeNet-5\nmodel2 = LeNet5()\noptimizer2 = optim.Adam(model2.parameters(), lr=0.001)\n\n# Architecture 3: Custom CNN\nmodel3 = CustomCNN()\noptimizer3 = optim.Adam(model3.parameters(), lr=0.001)\n\n# Architecture 4: MobileNetV2\nmodel4 = MobileNetV2()\noptimizer4 = optim.Adam(model4.parameters(), lr=0.001)\n\n# Architecture 5: VGGLike\nmodel5 = VGGLike()\noptimizer5 = optim.Adam(model5.parameters(), lr=0.001)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-02T10:30:06.100194Z","iopub.execute_input":"2023-06-02T10:30:06.100854Z","iopub.status.idle":"2023-06-02T10:30:06.199553Z","shell.execute_reply.started":"2023-06-02T10:30:06.100820Z","shell.execute_reply":"2023-06-02T10:30:06.198412Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Train and evaluate the models\nnum_epochs = 10\n\nfor epoch in range(num_epochs):\n    train_model(model1, train_loader, optimizer1, criterion)\n    train_model(model2, train_loader, optimizer2, criterion)\n    train_model(model3, train_loader, optimizer3, criterion)\n    train_model(model4, train_loader, optimizer4, criterion)\n    train_model(model5, train_loader, optimizer5, criterion)\n\n    acc1 = evaluate_model(model1, test_loader)\n    acc2 = evaluate_model(model2, test_loader)\n    acc3 = evaluate_model(model3, test_loader)\n    acc4 = evaluate_model(model4, test_loader)\n    acc5 = evaluate_model(model5, test_loader)\n\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n    print(f\"Accuracy - Simple CNN: {acc1:.2f}%, LeNet-5: {acc2:.2f}%, Custom CNN: {acc3:.2f}%, MobileNetV2: {acc4:.2f}%, VGGLike: {acc5:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2023-06-02T10:31:10.662462Z","iopub.execute_input":"2023-06-02T10:31:10.662822Z","iopub.status.idle":"2023-06-02T10:31:57.771919Z","shell.execute_reply.started":"2023-06-02T10:31:10.662792Z","shell.execute_reply":"2023-06-02T10:31:57.770896Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Train and evaluate the models\nnum_epochs = 10\n\nfor epoch in range(num_epochs):\n    train_model(model1, train_loader, optimizer1, criterion)\n#     train_model(model2, train_loader, optimizer2, criterion)\n#     train_model(model3, train_loader, optimizer3, criterion)\n#     train_model(model4, train_loader, optimizer4, criterion)\n#     train_model(model5, train_loader, optimizer5, criterion)\n\n    acc1 = evaluate_model(model1, test_loader)\n#     acc2 = evaluate_model(model2, test_loader)\n#     acc3 = evaluate_model(model3, test_loader)\n#     acc4 = evaluate_model(model4, test_loader)\n#     acc5 = evaluate_model(model5, test_loader)\n\n    print(f\"Epoch {epoch+1}/{num_epochs} Accuracy {acc1}\")\n#     print(f\"Accuracy - Simple CNN: {acc1:.2f}%, LeNet-5: {acc2:.2f}%, Custom CNN: {acc3:.2f}%, MobileNetV2: {acc4:.2f}%, VGGLike: {acc5:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2023-06-02T11:11:59.816861Z","iopub.execute_input":"2023-06-02T11:11:59.817229Z","iopub.status.idle":"2023-06-02T11:21:54.425836Z","shell.execute_reply.started":"2023-06-02T11:11:59.817195Z","shell.execute_reply":"2023-06-02T11:21:54.424719Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Epoch 1/10 Accuracy 65.92\nEpoch 2/10 Accuracy 65.87\nEpoch 3/10 Accuracy 65.29\nEpoch 4/10 Accuracy 65.6\nEpoch 5/10 Accuracy 65.97\nEpoch 6/10 Accuracy 66.5\nEpoch 7/10 Accuracy 65.72\nEpoch 8/10 Accuracy 66.58\nEpoch 9/10 Accuracy 66.31\nEpoch 10/10 Accuracy 66.3\n","output_type":"stream"}]},{"cell_type":"code","source":"acc1 = evaluate_model(model1, test_loader)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T10:31:57.774186Z","iopub.execute_input":"2023-06-02T10:31:57.774565Z","iopub.status.idle":"2023-06-02T10:32:03.438518Z","shell.execute_reply.started":"2023-06-02T10:31:57.774531Z","shell.execute_reply":"2023-06-02T10:32:03.437578Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"acc1","metadata":{"execution":{"iopub.status.busy":"2023-06-02T10:32:46.064539Z","iopub.execute_input":"2023-06-02T10:32:46.064895Z","iopub.status.idle":"2023-06-02T10:32:46.071650Z","shell.execute_reply.started":"2023-06-02T10:32:46.064867Z","shell.execute_reply":"2023-06-02T10:32:46.070762Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"52.78"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-06-02T10:45:44.274180Z","iopub.execute_input":"2023-06-02T10:45:44.274883Z","iopub.status.idle":"2023-06-02T10:45:44.924583Z","shell.execute_reply.started":"2023-06-02T10:45:44.274849Z","shell.execute_reply":"2023-06-02T10:45:44.923239Z"},"trusted":true},"execution_count":12,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m acc3 \u001b[38;5;241m=\u001b[39m evaluate_model(model3, test_loader)\n","Cell \u001b[0;32mIn[3], line 6\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, optimizer, criterion)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m      5\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 6\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[1;32m      8\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","Cell \u001b[0;32mIn[2], line 75\u001b[0m, in \u001b[0;36mCustomCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     73\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu3(x)\n\u001b[1;32m     74\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (128x131072 and 8192x10)"],"ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (128x131072 and 8192x10)","output_type":"error"}]},{"cell_type":"code","source":"# Architecture 3: Custom CNN with three convolutional layers\nclass CustomCNN(nn.Module):\n    def __init__(self):\n        super(CustomCNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n        self.relu1 = nn.ReLU()\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.relu2 = nn.ReLU()\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.relu3 = nn.ReLU()\n        self.fc = nn.Linear(128 * 32 * 32, 10)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.relu1(x)\n        x = self.conv2(x)\n        x = self.relu2(x)\n        x = self.conv3(x)\n        x = self.relu3(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2023-06-02T10:48:32.912939Z","iopub.execute_input":"2023-06-02T10:48:32.913300Z","iopub.status.idle":"2023-06-02T10:48:32.922633Z","shell.execute_reply.started":"2023-06-02T10:48:32.913268Z","shell.execute_reply":"2023-06-02T10:48:32.921733Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model3 = CustomCNN()\noptimizer3 = optim.Adam(model3.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T10:49:33.441453Z","iopub.execute_input":"2023-06-02T10:49:33.441801Z","iopub.status.idle":"2023-06-02T10:49:33.458939Z","shell.execute_reply.started":"2023-06-02T10:49:33.441772Z","shell.execute_reply":"2023-06-02T10:49:33.457967Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_model(model3, train_loader, optimizer3, criterion)\nacc3 = evaluate_model(model3, test_loader)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T10:49:36.474547Z","iopub.execute_input":"2023-06-02T10:49:36.474894Z","iopub.status.idle":"2023-06-02T10:58:45.059186Z","shell.execute_reply.started":"2023-06-02T10:49:36.474866Z","shell.execute_reply":"2023-06-02T10:58:45.058139Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"acc3","metadata":{"execution":{"iopub.status.busy":"2023-06-02T10:58:45.061147Z","iopub.execute_input":"2023-06-02T10:58:45.061599Z","iopub.status.idle":"2023-06-02T10:58:45.069227Z","shell.execute_reply.started":"2023-06-02T10:58:45.061565Z","shell.execute_reply":"2023-06-02T10:58:45.068380Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"46.85"},"metadata":{}}]},{"cell_type":"code","source":"num_epochs = 10\n\nfor epoch in range(num_epochs):\n    train_model(model1, train_loader, optimizer1, criterion)\n\n    acc1 = evaluate_model(model1, test_loader)\n\n\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n    print(f\"Accuracy - Simple CNN: {acc1:.2f}%\")","metadata":{},"execution_count":null,"outputs":[]}]}